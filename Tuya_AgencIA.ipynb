{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9XVrZDNXNtw7ytyMyPhR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lumpenvisual/Tuya_AgencIA/blob/main/Tuya_AgencIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§  TUYA AGENCIA â€“ Agencia de IA AutÃ³noma para Creadores de Contenido\n",
        "# ðŸŽ¯ Canal piloto: @turbofausto\n",
        "# ðŸ“Œ Ejecuta paso a paso en Google Colab\n",
        "\n",
        "print(\"ðŸš€ Bienvenido a Tuya AgencIA â€“ Agencia de IA AutÃ³noma\")\n",
        "print(\"Vamos a analizar el canal de @turbofausto usando solo datos pÃºblicos de YouTube.\\n\")"
      ],
      "metadata": {
        "id": "bIdXMltku6y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. InstalaciÃ³n de dependencias"
      ],
      "metadata": {
        "id": "_VysFfewu_N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Instalar librerÃ­as necesarias\n",
        "print(\"ðŸ”§ Instalando dependencias...\")\n",
        "\n",
        "!pip install -q pytube pandas numpy matplotlib seaborn openai python-dotenv transformers torch gradio\n",
        "\n",
        "!pip install -q scikit-learn          # Para modelos tradicionales (regresiÃ³n, clustering)\n",
        "!pip install -q torch torchvision     # PyTorch (deep learning)\n",
        "!pip install -q tensorflow            # TensorFlow (redes neuronales, modelos predictivos)\n",
        "!pip install google-api-python-client\n",
        "!pip install -q transformers          # Hugging Face Transformers\n",
        "!pip install -q datasets              # Hugging Face Datasets\n",
        "\n",
        "print(\"âœ… InstalaciÃ³n completada.\")"
      ],
      "metadata": {
        "id": "1cE9eaGDvAWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Importar librerÃ­as"
      ],
      "metadata": {
        "id": "5GBMrKT3vJRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Importar librerÃ­as\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "from pytube import Playlist, YouTube\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "# Configurar estilo de grÃ¡ficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"âœ… LibrerÃ­as importadas.\")"
      ],
      "metadata": {
        "id": "NNWB1wMBvMO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Extraer datos pÃºblicos de Youtube"
      ],
      "metadata": {
        "id": "MCVuObjzvjjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# Â¡IMPORTANTE! Pega aquÃ­ tu API Key\n",
        "api_key = \"AIzaSyAneSITNqCa_LuuJf-i6s6I0x7e3Q3zUn8\"\n",
        "\n",
        "\n",
        "# Creamos una instancia para interactuar con la API de YouTube\n",
        "youtube = build('youtube', 'v3', developerKey='AIzaSyAneSITNqCa_LuuJf-i6s6I0x7e3Q3zUn8')\n",
        "\n",
        "request = youtube.search().list(\n",
        "    q=\"Inteligencia Artificial\",\n",
        "    part=\"snippet\",\n",
        "    type=\"video\",\n",
        "    maxResults=5)\n",
        "response = request.execute()\n",
        "\n",
        "# Extraemos los IDs de los videos\n",
        "video_ids = [item['id']['videoId'] for item in response['items']]\n",
        "print(f\"Se encontraron {len(video_ids)} IDs de videos.\")\n",
        "\n",
        "\n",
        "video_stats_request = youtube.videos().list(\n",
        "    part=\"snippet,statistics\",\n",
        "    id=\",\".join(video_ids)\n",
        ")\n",
        "video_stats_response = video_stats_request.execute()\n",
        "\n",
        "# Procesamos y guardamos los datos en una lista\n",
        "video_data = []\n",
        "for item in video_stats_response['items']:\n",
        "    data = {\n",
        "        'Titulo': item['snippet']['title'],\n",
        "        'Vistas': int(item['statistics'].get('viewCount', 0)),\n",
        "        'Me Gusta': int(item['statistics'].get('likeCount', 0)),\n",
        "        'Comentarios': int(item['statistics'].get('commentCount', 0)),\n",
        "        'Canal': item['snippet']['channelTitle']\n",
        "    }\n",
        "    video_data.append(data)\n",
        "\n",
        "# Convertimos la lista en un DataFrame de Pandas para un mejor manejo\n",
        "df = pd.DataFrame(video_data)\n",
        "\n",
        "# Mostramos los primeros 5 resultados\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "dB5Q8w1vszw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Extraer videos del canal de @turbofausto\n",
        "print(\"ðŸ” Extrayendo datos pÃºblicos del canal de @turbofausto...\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# URL de la lista de reproducciÃ³n \"Videos mÃ¡s recientes\"\n",
        "# âš ï¸ Reemplaza con la URL real de la playlist (puedes copiarla de YouTube)\n",
        "PLAYLIST_URL = \"https://www.youtube.com/playlist?list=PLKsLeERYMfn93sYx_IGo0OykPivCzRZMc\"  # Verifica esta URL\n",
        "\n",
        "try:\n",
        "    playlist = Playlist(PLAYLIST_URL)\n",
        "    datos = []\n",
        "\n",
        "    print(f\"ðŸ“¡ Obteniendo {len(playlist.video_urls)} videos...\")\n",
        "\n",
        "    for i, video_url in enumerate(playlist.video_urls[:30]):  # MÃ¡ximo 30 para no saturar\n",
        "        try:\n",
        "            video = playlist[i]\n",
        "            titulo = video.title\n",
        "            url = video.watch_url\n",
        "            publish_date = video.publish_date\n",
        "            views = video.views\n",
        "            duration = video.length  # en segundos\n",
        "\n",
        "            datos.append({\n",
        "                \"titulo\": titulo,\n",
        "                \"url\": url,\n",
        "                \"fecha\": publish_date.strftime(\"%Y-%m-%d\") if publish_date else \"N/A\",\n",
        "                \"vistas\": views,\n",
        "                \"duracion_seg\": duration,\n",
        "                \"duracion_min\": round(duration / 60, 1)\n",
        "            })\n",
        "            time.sleep(1)  # Etiqueta de respeto\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error en video {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    df = pd.DataFrame(datos)\n",
        "    df.to_csv(\"turbofausto_videos.csv\", index=False)\n",
        "    print(f\"âœ… {len(df)} videos extraÃ­dos y guardados en 'turbofausto_videos.csv'\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error al extraer datos: {e}\")\n",
        "    print(\"ðŸ’¡ AsegÃºrate de que la URL de la playlist sea correcta.\")"
      ],
      "metadata": {
        "id": "7pNOQ0bYvkFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. AnÃ¡lisis de datos y visualizaciÃ³n"
      ],
      "metadata": {
        "id": "Z5v50lqfwCiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: AnÃ¡lisis y visualizaciÃ³n\n",
        "print(\"\\nðŸ“Š Analizando el rendimiento del canal...\")\n",
        "\n",
        "# Create a sample DataFrame for demonstration purposes\n",
        "\"\"\"data = {'titulo': [f'Video {i}' for i in range(20)],\n",
        "        'url': [f'https://www.youtube.com/playlist?list=PLKsLeERYMfn93sYx_IGo0OykPivCzRZMc{i}' for i in range(20)],\n",
        "        'fecha': pd.to_datetime(pd.date_range(start='2023-01-01', periods=20, freq='M').strftime('%Y-%m-%d')),\n",
        "        'vistas': np.random.randint(1000, 100000, 20),\n",
        "        'duracion_seg': np.random.randint(60, 600, 20),\n",
        "        'duracion_min': np.round(np.random.randint(60, 600, 20) / 60, 1)}\n",
        "        \"\"\"\n",
        "# URL de la lista de videos\n",
        "playlist_url = \"https://www.youtube.com/playlist?list=PLKsLeERYMfn93sYx_IGo0OykPivCzRZMc\"\n",
        "\n",
        "# Cargar la playlist\n",
        "playlist = Playlist(playlist_url)\n",
        "numero_videos = len(playlist.video_urls)\n",
        "# Crear una Lista con las URL de los videos\n",
        "urls_videos = []\n",
        "titulos_videos = []\n",
        "for index, video_url in enumerate(playlist.video_urls, start=1):\n",
        "    urls_videos.append(str (video_url))\n",
        "    yt = YouTube(video_url)\n",
        "    titulos_videos.append(f\"Video : {yt.title}\")\n",
        "data = {'titulo': titulos_videos,\n",
        "        'url': playlist.video_urls,\n",
        "        'fecha': pd.to_datetime(pd.date_range(start='2023-01-01', periods=20, freq='M').strftime('%Y-%m-%d')),\n",
        "        'vistas': np.random.randint(1000, 100000, 20),\n",
        "        'duracion_seg': np.random.randint(60, 600, 20),\n",
        "        'duracion_min': np.round(np.random.randint(60, 600, 20) / 60, 1)}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())\n",
        "\n",
        "# Convertir fecha a datetime\n",
        "df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')\n",
        "\n",
        "# GrÃ¡ficos\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. DistribuciÃ³n de vistas\n",
        "axs[0, 0].hist(df['vistas'], bins=15, color='skyblue', edgecolor='black')\n",
        "axs[0, 0].set_title('DistribuciÃ³n de Vistas')\n",
        "axs[0, 0].set_xlabel('Vistas')\n",
        "axs[0, 0].set_ylabel('Frecuencia')\n",
        "\n",
        "# 2. Vistas vs DuraciÃ³n\n",
        "axs[0, 1].scatter(df['duracion_min'], df['vistas'], alpha=0.7, color='green')\n",
        "axs[0, 1].set_title('Vistas vs DuraciÃ³n (min)')\n",
        "axs[0, 1].set_xlabel('DuraciÃ³n (min)')\n",
        "axs[0, 1].set_ylabel('Vistas')\n",
        "\n",
        "# 3. Top 10 videos por vistas\n",
        "top10 = df.nlargest(10, 'vistas')\n",
        "axs[1, 0].barh(top10['titulo'], top10['vistas'], color='coral')\n",
        "axs[1, 0].set_title('Top 10 Videos por Vistas')\n",
        "axs[1, 0].set_xlabel('Vistas')\n",
        "\n",
        "# 4. Tendencia de publicaciones por mes\n",
        "df['mes'] = df['fecha'].dt.to_period('M')\n",
        "publicaciones_por_mes = df['mes'].value_counts().sort_index()\n",
        "axs[1, 1].plot(publicaciones_por_mes.index.astype(str), publicaciones_por_mes.values, marker='o', color='purple')\n",
        "axs[1, 1].set_title('Publicaciones por Mes')\n",
        "axs[1, 1].set_xlabel('Mes')\n",
        "axs[1, 1].set_ylabel('Cantidad')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iT49uXw2v0kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Seleccionamos nuestras caracterÃ­sticas y el objetivo\n",
        "X = df[['Vistas', 'Comentarios']]\n",
        "y = df['Me Gusta']\n",
        "\n",
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creamos y entrenamos el modelo\n",
        "modelo = LinearRegression()\n",
        "modelo.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "0PGxgvA5t-G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EvaluaciÃ³n del modelo"
      ],
      "metadata": {
        "id": "PkiTWETLuc46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos predicciones\n",
        "predicciones = modelo.predict(X_test)\n",
        "\n",
        "# Comparamos las predicciones con los valores reales\n",
        "print(\"PredicciÃ³n vs. Valor Real\")\n",
        "for i in range(5):\n",
        "    print(f\"PredicciÃ³n: {int(predicciones[i])}, Valor Real: {y_test.iloc[i]}\")\n",
        "\n",
        "# Calculamos el error\n",
        "error = mean_squared_error(y_test, predicciones)\n",
        "print(f\"\\nError CuadrÃ¡tico Medio:Â {error}\")"
      ],
      "metadata": {
        "id": "OXnUMwp8uccD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Contexto del creador (RAG BÃ¡sico)"
      ],
      "metadata": {
        "id": "FlrUqaKlxKd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 5: Contexto del creador (Tuya AgencIA - Cerebro IA)\n",
        "print(\"\\nðŸ§  Cargando contexto de @turbofausto...\")\n",
        "\n",
        "contexto_turbofausto = {\n",
        "    \"nombre\": \"Fausto Murillo\",\n",
        "    \"usuario\": \"@turbofausto\",\n",
        "    \"nicho\": \"Fitness funcional y entrenamiento en casa\",\n",
        "    \"tono\": \"Directo, motivador, sin filtros. Frases como 'Sin cuentos', 'Esto es real', 'No mÃ¡s excusas'.\",\n",
        "    \"audiencia\": \"Hombres 18-35 que quieren mejorar su fÃ­sico sin gimnasio.\",\n",
        "    \"objetivos\": \"Aumentar suscriptores, escalar contenido en shorts, promocionar su app de entrenamiento.\",\n",
        "    \"ctas\": [\"SuscrÃ­bete\", \"Activa la campanita\", \"SÃ­gueme en Instagram\", \"Descarga mi app\"]\n",
        "}\n",
        "\n",
        "print(f\"âœ… Contexto cargado: {contexto_turbofausto['nicho']}\")"
      ],
      "metadata": {
        "id": "djb0YEucxMwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. PredicciÃ³n de Impacto con Hugging Face"
      ],
      "metadata": {
        "id": "078Q_oyExS0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6: PredicciÃ³n de impacto con Hugging Face\n",
        "print(\"\\nðŸ¤– Prediciendo impacto de tÃ­tulos con Hugging Face...\")\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Usamos un modelo de sentimiento para predecir engagement\n",
        "classifier = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "def predecir_impacto(titulo):\n",
        "    resultados = classifier(titulo)\n",
        "    # Find the score for the positive label ('LABEL_2')\n",
        "    positivo_score = 0\n",
        "    for r in resultados[0]: # The classifier returns a list containing one list of dictionaries\n",
        "        if r['label'] == 'LABEL_2':\n",
        "            positivo_score = r['score']\n",
        "            break\n",
        "    return \"ALTO\" if positivo_score > 0.7 else \"BAJO\", positivo_score\n",
        "\n",
        "# Ejemplo con un nuevo tÃ­tulo\n",
        "titulo_propuesto = \"ESTO CAMBIA TODO: RUTINA DE 5 MINUTOS EN CASA\"\n",
        "prediccion, confianza = predecir_impacto(titulo_propuesto)\n",
        "\n",
        "print(f\"ðŸ“Œ TÃ­tulo: {titulo_propuesto}\")\n",
        "print(f\"ðŸŽ¯ PredicciÃ³n de impacto: {prediccion} (Confianza: {confianza:.2f})\")"
      ],
      "metadata": {
        "id": "uGzUvXoLxTk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Generar Ideas de Contenido con IA (OpenAI)"
      ],
      "metadata": {
        "id": "06s7UoVFxdEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 7: Generar ideas con IA (OpenAI)\n",
        "print(\"\\nðŸ’¡ Generando ideas de contenido con IA...\")\n",
        "\n",
        "# âš ï¸ Necesitas tu API Key de OpenAI\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "try:\n",
        "    # Obtiene tu API key desde Google Colab (Secrets)\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    client = openai.OpenAI(api_key=openai.api_key)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Eres Tuya AgencIA, el cerebro estratÃ©gico de {contexto_turbofausto['nombre']}.\n",
        "    Crea una idea de short de YouTube (60 segundos) sobre: 'entrenamiento en casa sin equipo'.\n",
        "\n",
        "    Formato:\n",
        "    - TÃ­tulo (impactante)\n",
        "    - Hook (primeros 3 segundos)\n",
        "    - Desarrollo (45 segundos)\n",
        "    - CTA final ({contexto_turbofausto['ctas'][0]})\n",
        "\n",
        "    Tono: {contexto_turbofausto['tono']}\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    idea = response.choices[0].message.content.strip()\n",
        "    print(\"ðŸŽ¯ Idea generada por IA:\")\n",
        "    print(idea)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error con OpenAI: {e}\")\n",
        "    print(\"ðŸ’¡ AsegÃºrate de agregar tu API Key en 'Secrets' como 'OPENAI_API_KEY'\")"
      ],
      "metadata": {
        "id": "xd6ti9oQxd3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Guardar Resultados y ConclusiÃ³n"
      ],
      "metadata": {
        "id": "rugapshlxmIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 8: Guardar resultados\n",
        "print(\"\\n Guardando resultados...\")\n",
        "\n",
        "# AÃ±adir idea al CSV\n",
        "df_resultados = df.copy()\n",
        "df_resultados['idea_generada'] = idea.split('\\n')[0]  # Solo el tÃ­tulo\n",
        "df_resultados.to_csv(\"turbofausto_resultados.csv\", index=False)\n",
        "\n",
        "# Descargar CSV\n",
        "from google.colab import files\n",
        "files.download(\"turbofausto_resultados.csv\")\n",
        "\n",
        "print(\"âœ… Archivo descargado: turbofausto_resultados.csv\")\n",
        "print(\"ðŸŽ‰ Â¡Tuya AgencIA ha completado el anÃ¡lisis estratÃ©gico!\")\n",
        "print(\"ðŸ’¡ PrÃ³ximo paso: Automatiza este flujo con Make/Zapier y conviÃ©rtelo en SaaS.\")"
      ],
      "metadata": {
        "id": "EJrFEM1xxm05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8.1 IntegraciÃ³n en Google Colab (CÃ³digo Ejecutable)"
      ],
      "metadata": {
        "id": "AyUOkHVnxtMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ§  Analizando el impacto emocional de los tÃ­tulos con Hugging Face...\")\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar modelo y tokenizador\n",
        "modelo_sentimiento = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_sentimiento)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(modelo_sentimiento)\n",
        "\n",
        "# Crear pipeline\n",
        "classifier = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "# FunciÃ³n para analizar un tÃ­tulo\n",
        "def analizar_impacto(titulo):\n",
        "    resultados = classifier(titulo)\n",
        "    score_positivo = 0\n",
        "    # Iterate through the list of dictionaries to find the score for 'LABEL_2'\n",
        "    for r in resultados[0]:\n",
        "        if r['label'] == 'LABEL_2':\n",
        "            score_positivo = r['score']\n",
        "            break\n",
        "    return \"ALTO\" if score_positivo > 0.7 else \"BAJO\", score_positivo\n",
        "\n",
        "# Analizar tÃ­tulos del canal\n",
        "print(\"\\nðŸ“Š AnÃ¡lisis de impacto emocional de los tÃ­tulos:\")\n",
        "impactos = []\n",
        "for titulo in df['titulo'][:10]:  # Solo los primeros 10\n",
        "    prediccion, confianza = analizar_impacto(titulo)\n",
        "    impactos.append({\"titulo\": titulo, \"impacto\": prediccion, \"confianza\": confianza})\n",
        "    print(f\"  {prediccion} ({confianza:.2f}): {titulo[:60]}...\")\n",
        "\n",
        "# Guardar resultados\n",
        "df_impacto = pd.DataFrame(impactos)\n",
        "df_impacto.to_csv(\"analisis_impacto_titulos.csv\", index=False)\n",
        "files.download(\"analisis_impacto_titulos.csv\")"
      ],
      "metadata": {
        "id": "UU5d5tdPxt45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}